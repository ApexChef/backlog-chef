# Backlog Chef - Environment Variables
# Copy this file to .env and configure your settings

# =============================================================================
# AI PROVIDER CONFIGURATION
# =============================================================================

# Anthropic Claude (Primary - Recommended)
ANTHROPIC_API_KEY=sk-ant-your-api-key-here

# OpenAI (Alternative)
# OPENAI_API_KEY=sk-proj-your-api-key-here

# Google Gemini (Alternative)
# GOOGLE_API_KEY=your-google-api-key-here

# Azure OpenAI (Alternative)
# AZURE_OPENAI_API_KEY=your-azure-key-here
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_DEPLOYMENT=gpt-4o

# Local Ollama (No API key needed - just run: ollama serve)
# OLLAMA_ENDPOINT=http://localhost:11434

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Override default models (optional)
# CLAUDE_MODEL=claude-3-5-haiku-20241022
# OPENAI_MODEL=gpt-4o-mini
# GEMINI_MODEL=gemini-1.5-flash

# =============================================================================
# COST MANAGEMENT
# =============================================================================

# Cost limits in USD (optional - defaults shown)
# COST_LIMIT_PER_RUN_USD=1.0
# COST_ALERT_THRESHOLD_USD=0.5
# DAILY_COST_LIMIT_USD=10.0

# =============================================================================
# PIPELINE CONFIGURATION
# =============================================================================

# Retry Configuration
# MAX_RETRIES=3
# RETRY_DELAY=1000

# Processing Configuration
# MAX_CONCURRENT_ANALYSES=5
# ANALYSIS_TIMEOUT_MS=30000

# Confidence thresholds
# CONFIDENCE_THRESHOLD=0.7
# MAX_TRANSCRIPT_LENGTH=20000

# =============================================================================
# INPUT/OUTPUT CONFIGURATION
# =============================================================================

# Input/Output paths (optional overrides)
# INPUT_FILE=path/to/transcript.txt
# OUTPUT_DIR=output

# Output Formats (comma-separated: markdown,devops,confluence)
# OUTPUT_FORMATS=markdown,devops,confluence

# =============================================================================
# LOGGING & DEBUG
# =============================================================================

# Logging Configuration
# LOG_LEVEL=info
# LOG_FILE=backlog-chef.log

# Debug Mode (set to true for verbose logging)
# DEBUG=false

# =============================================================================
# QUICK START
# =============================================================================
#
# 1. Copy this file: cp .env.example .env
# 2. Add your API key: Edit ANTHROPIC_API_KEY above
# 3. Run: npm start
#
# For more details, see TESTING.md
